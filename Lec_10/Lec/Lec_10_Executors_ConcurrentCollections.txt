* Runnable vs Callable

    Това са два основни интерфейса в Java като се използват за създаване на задачи, които се изпълняват паралелно (тоест в нишки)

    (Runnable)
    Методът на Runnable е run() и е void, тоест задачата свършва работата си, но не връща резултат
    Тя не може да хвърли checked exception, а ако възникне грешка тя трябва да се обработни в самият метод на thread-a
    Най-подходящ е този интерфейс за задачи тип от "fire-and-forget" (пускаш и забравяш)

    @FunctionInterface
    public interface Runnable{
        void run();
    }

    (Callable)
    Методът call() връща стойност V (защото Callable е генеричен интерфейс), тоест след прикюлчването на работата се връща резултат
    Може да хвърля checked exceptions
    Използва се, когато трябва резултат от изчисленията или за по-добър контрол над грешките

    @FunctionInterface
    public interface Callable<V> {
        V call() throws Exception;
    }

* Future

    Future е пряко свързан със Callable, защото е интерфейс, който представлява резултата от асинхронно изчисление
    # Асинхронното изчисление може да се случи когато Callble интерфейс се стартира от ExecutorService по такъв начин 

    Този интефрейс съдържа следните методи:
    - V get(): когато бъде извикан, текущата нишка спира изпълнението си (тоест влиза в WAITING) и чака, докато асинхронната задача приключи.
    # При успех връща резултат от тип V, ако има грешка в задачата хвърля ExecutionException, а при прекъсване хвърля InterruptedException
    - V get(long timeout, TimeUnit unit): версия на get с timeout, като блокира нишката само за указания период
    # Ако задачата не приключи в рамките на това време, методът хвърля TimeoutException
    - boolean cancel(boolean mayInterruptIfRunning): опит за прекратяване на изпълнението на задачата 
    # Ако задачата не е стартира, тя се маха от опашката, а ако работи параметърът mayInterruptIfRunning определя дали нишката да бъде прекъсната с thread.interrupt(), но резултата ще бъде игнориран
    - boolean isDone(): връща true, ако задачата е приключила
    # Ще бъде приключила, ако нормалено е завършила или се е хвърлило изключение или е отказано с cancel() 
    - boolean isCancelled(): връща true, само ако задачата е била успешно отказана

* Thread pool

    Thread pool-a е архитектурен модел за управление на конкуретно изпълнение като използва нишките многократно с цел оптимизация
    Runnable или Callable обекти се третират като "задачи" и се трупат в опашка, и когато има свободни нишки в pool-а, те изпълняват задачите, на базата на зададени правила.

    Погледна диаграмата TheadPoolQueue, следната диаграма работи по следния начин:
    - Task Queue: Тук са инстанциите на обектите на Runnable и Callable и ако всичктие нишки са заети, задачите чакат тук вместо да се отхвърлят или да блокират извикващ код
    - Worker Threads: Вместо да се стартира нова нишка за всяка задача се поддържа фиксиран брой живи нишки, като една такава взима задача от опашката изпълнява ч и не умира след края и
    - Оптимизация: Това драстично намалява натоварването на процесора и паметта, защото избягва скъпата операция за създаване на нишки 

* Executors API: Executor, ExecutorService, ScheduledExecutorService 

    Става дума за йерархията в Executors API в java.util.concurrent, която надгражда функционалността за управление на задачи

    void execute(Runnable command)
    # Executor е базовият интерфейс, който дефинира метода execute(Runnable command) за изпълнение на задачи, които не връщат резултат

    <T> Future<T> submit(Callable<T> task)
    # ExecutorService е интерфейс, който разширява функционалността като може да изпълнява Callable обекти, тук метода submit връща Future<T>

    ScheduledFuture<?> schedule(Runnable r, long delay, TimeUnit tu)
    # Стартира подаденият Runnable само веднъж, след като изтече delay, тоест има еднократно изпълнение
    ScheduledFuture<?> scheduleAtFixedRate(Runnable r, long initialDelay, long period, TimeUnit tu)
    # Стартира Runnable-a периодично на всеки зададен period, като има първоначален delay чрез initialDelay
    ScheduledFuture<?> scheduleWithFixedDelay(Runnable r, long initialDelay, long delay, TimeUnit tu)
    # ScheduledExecutorService e интерфейс, който позволява планиране във времето, чрез него задачите могат да се пускат след определено закъснение или периодично

* Създаване на Executor, работещ с платформени нишки

    Ще се разгледат статични методи в класа Executors, чрез които се създават различни видове thread pools:
    - static ExecutorService newSingleThreadExecutor()
    # pool-ът ще се състои само от една нишка, следователно задачите ще се изпълняват последователно
    - static ExecutorService newFixedThreadPool(int n)
    # създава се pool, който ще се състои от фиксиран брой нишки, aко в опашката има повече задачи, отколкото налични нишки, задачите няма да се обработват, докато не се освободи нишка
    - static ExecutorService newCachedThreadPool()
    # създава се pool от нишки, който ще преизползва нишките, ако има налични, в противен случай ще направи нови
    - static ScheduledExecutorService newScheduledThreadPool(int size)
    # pool, който изпълнява задачи периодично или със закъснение

* Създаване на Executor, работещ с виртуални нишки

    - static ExecutorService newVirtualThreadPerTaskExecutor()
    # Този метод създава ExecutorService, който автоматично стартира нова виртуална нишка за всяка една задача и след това я унищожава, когато задачата приключи
    
    Алтернативния начин е чрез:
    Executors.newThreadPerTaskExecutor(Thread.ofVirtual().factory());

* Спиране на Thread pool 

    Основното правило е че когато се приключи работа с един Executor, задължително трябва да се спре, в противен случай JVM може да продължи да работи и програмата няма да се затвори сама 

    Има два начина това да се направи:
    - Ръчно: чрез executor.shutdown()
    - Автоматично: използвайки try-with-resources, понеже ExecutorService е AutoCloseable, ако той се дефинира в скобите на try блока той ще бъде автоматично затворен чрез .shutdown()

* Structured Concurrency

    Това цели да въведе ред в хаоса на паралелните задачи

    Вместо да се пускат нишки, които да бъдат независими, се групират няколко задачи в една логическа операция
    Това работи като всички подзадачи започват и завършват в един и същи блок код, като се гарантира, че ако главната задача приключи то всички стартирани от нея поднишки ще бъдат автоматично спрени
    Кодът става по-четлив и предсказуем и по-лесен за дебъгване

    StructuredTaskScope e класът, който реализира тази идея, той работи на следния принцип:
    - fork(): Стартира нова подзадача вътре в обхвата
    - join(): Изчаква всички стартирани задачи да приключат
    # Гаранцията е че когато блокът приключи, няма да има опасност да останат забравени нишки 

    Виж StructuredTaskScopeЕxample.java за да ги разбереш нещата:

* Thread-safe колекции: Синхронизирани колекции

    Обикновените колекции (примерно ArrayList и HashMap) ще се счупят, ако няколко нишки пишат в тях едновременно

    Collections API предоставя имплементации на няколко синхронизирани колекции като  Vector и Hashtable, но те старият и базов начин да ги защитим

    Методът static <T> Collection<T> synchronizedCollection(Collection<T> c) e factory метод, с който можем да създадем synchronized колекция от съществуваща обикновена колекция
    Проблема на синхронизираните колекции е че не са достатъчно бързи при много едновременни ползватели и не предоставят възможност за атомарни операции 

* Thread-safe колекции: Concurrent колекции

    За разлика от синхронизираните колекции, които заключваха данните, тези са проектирани изначално за скорост и ефективност
    Имат три ключови предимства:
    - Lock-free паралелен достъп: Старите колекции заключват целия списък, дори само една нишка да чете, докато concurrent колекциите използват умни алгоритми, коити позволяват много нишки да четат и пишат едновременно, без да се блокират
    - Атомарни операции
    - Fail-safe итератор: concurrent колекциите позволяват спокойно четене дори и данните да се променят
    # При обикновеннните списъци, ако е направен опит за четене докато някой друг добавя елемент ще се хвърли ConcurrentModificationException

* CopyOnWriteArrayList

    Тази структура е създадена специално за паралелно програмиране

    Тя има следните характеристики:
    - Позволява lock-free паралелно четене
    - "Fail-safe snapshot" итератор
    - Всяка модификация предизвиква копиране на масива
    # Копирането се прави тъй като писането става върху ново копие, никой не пипа стария масив, докато другите нишки го четат, така четенето е бързо и не блокира
    - Атомарни операции: boolean addIfAbsent(E e)

    Използването на тази структура е подходящо, само когато броят на четенията от масива значително надвишава броя на модификациите

* ConcurrentHashMap

    Тази структура е създадена специално за паралелно програмиране

    Тя има следните характеристики:
    - Паралелен lock-free достъп за четене
    - Паралелен (но лимитиран) достъп за писане
    # Вместо да заключва цялата карта, тя заключва само малка част от нея (тоест даден bucket) където се намира конкретния запис, така други нишки могат да пишат в други части на картата по същото време
    - Fail-safe и "Weakly consistent" итератор
    # Може да се върти foreach цикъл през картата, докато друга нишка добавя или трие записи, и програмата няма да гръмне с грешка
    - Атомарни операции: V putIfAbsent(K key, V value)

    Това е най-популярната колекция от java.util.concurrent библиотеката, почти винаги е подходяща да се използва за замяната на старите синхронизирани варианти на HashMap

* BlockingQueue<E>

    Това е най-важният интерфейс за организиране на работата между различни нишки, известна като модела "Producer-Consumer"

    Какво всъщност представлява, първоначално си представи един буфер между две групи нишки:
    - Producer са нишките, които създават задачи и ги слагат на лентата
    - Consumer са нишките, които взимат задачи от лентата и ги изпълняват

    Тази структура автоматично блокира нишките, когато е необходимо:
    - Ако опашката е ПЪЛНА, тоест когато производителят се опита да добави нов елемент, той е автоматично блокиран и чака, докато се освободи място
    - Ако опашката е ПРАЗНА, тоест когато потребителят се опита да вземе елемент, той е блокиран и чака докато някой добави нещо ново

    Основните имплементации на този интерфейс са:
    - ArrayBlockingQueue<E> като пази елементите си в масив и не може да се resize-ва
    - LinkedBlockingQueue<E> като пази елементите си в свързан списък и може да е с фикзиран или динамичен размер